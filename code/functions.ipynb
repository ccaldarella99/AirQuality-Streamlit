{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87abdab0-143e-4de3-b3e5-a7b2774a48cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edbab38c-7e1f-45f6-ab88-63c9ad2ede09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel():\n",
    "    \"\"\"\n",
    "    Model (of your choice) for Classification\n",
    "    This Class takes X_train, X_test, y_train, and y_test and builds a Model\n",
    "    \n",
    "    ARGUMENTS (init)\n",
    "    ----------------\n",
    "    pipe: input a pipeline for your GridSearchCV Model to use\n",
    "    X_train: your X that trains your model\n",
    "    y_train: your y that trains your model\n",
    "    X_train: your X to test your model with\n",
    "    y_train: your y to test your model with\n",
    "    params: Parameters for the pipline\n",
    "    mod_name: Model Name shown in DataFrame\n",
    "    verbose: Sets verbosity of GridSearchCV (1, 2, or 3)\n",
    "    show_print_results: set to True prints scores after __init__ runs, else prints DataFrame\n",
    "    \n",
    "    RETURN\n",
    "    ------\n",
    "    Returns your model; assign the instance to variable to access your GridSearchCV object\n",
    "    \n",
    "    EXAMPLE\n",
    "    -------\n",
    "    #import model library\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    # instantiate\n",
    "    lr = RegressionModel(pipe, X_train, X_test, y_train, y_test, params={})\n",
    "    # show DataFrame of Scores (call the scores DataFrame object, df)\n",
    "    lr.df\n",
    "    \"\"\"\n",
    "    scores = {}\n",
    "    train_scores = {}\n",
    "    y_pred = None\n",
    "    y_train_pred = None\n",
    "    train_r2_score = None\n",
    "    test_r2_score = None\n",
    "    train_rmse = None\n",
    "    test_rmse = None\n",
    "    train_mse = None\n",
    "    test_mse = None\n",
    "    train_mae = None\n",
    "    test_mae = None\n",
    "    df = None\n",
    "    y_thresh = None\n",
    "        \n",
    "    def __init__(self, pipe, X_train, X_test, y_train, y_test, params={}, mod_name='', \n",
    "                 round_y_threshold = 0.5, invert_y=False, verbose=2, show_print_results=False):\n",
    "#         if(verbose > 1):\n",
    "        if(show_print_results):\n",
    "            print(datetime.datetime.now().strftime('START:  %Y-%m-%d, %H:%M:%S\\n'))\n",
    "        \n",
    "        self.model_name = mod_name\n",
    "        self.y_thresh = round_y_threshold\n",
    "\n",
    "        self.pipe = pipe\n",
    "        self.params = params\n",
    "        self.model = GridSearchCV(pipe, params, n_jobs=-1, verbose=verbose)\n",
    "        self.model.fit(X_train, y_train)\n",
    "        self.best_params_ = self.model.best_params_\n",
    "        if(len(mod_name) == 0):\n",
    "            self.model_name = str(type(self.pipe[-1])).split('.')[-1][:-2]\n",
    "        \n",
    "        if(invert_y):\n",
    "            self.y_pred = self.set_y_pred_inv(X_test)\n",
    "            self.y_train_pred = self.set_y_pred_inv(X_train)\n",
    "        else:\n",
    "            self.y_pred = self.set_y_pred(X_test)\n",
    "            self.y_train_pred = self.set_y_pred(X_train)\n",
    "\n",
    "        self.train_r2_score = self.set_r2_score(y_train, self.y_train_pred)\n",
    "        self.test_r2_score = self.set_r2_score(y_test, self.y_pred)\n",
    "        self.train_rmse = self.set_rmse(y_train, self.y_train_pred)\n",
    "        self.test_rmse = self.set_rmse(y_test, self.y_pred)\n",
    "        self.train_mse = self.set_mse(y_train, self.y_train_pred)\n",
    "        self.test_mse = self.set_mse(y_test, self.y_pred)\n",
    "        self.train_mae = self.set_mae(y_train, self.y_train_pred)\n",
    "        self.test_mae = self.set_mae(y_test, self.y_pred)\n",
    "        \n",
    "        self.set_all_score()\n",
    "        self.set_DataFrame()\n",
    "\n",
    "        if(show_print_results):# & verbose > 1):\n",
    "            self.print_results(y_train, y_test)\n",
    "    \n",
    "    def DataFrame(self):\n",
    "        return self.df\n",
    "    \n",
    "    def set_DataFrame(self):\n",
    "        train_df = pd.DataFrame(np.array([v for k,v in self.train_scores.items()]), \n",
    "                               index=[k for k,v in self.train_scores.items()], \n",
    "                               columns=[self.model_name])\n",
    "        test_df = pd.DataFrame(np.array([v for k,v in self.scores.items()]), \n",
    "                               index=[k for k,v in self.scores.items()], \n",
    "                               columns=[self.model_name])\n",
    "        self.df = pd.concat([test_df, train_df])#, axis=1)\n",
    "    \n",
    "    def print_results(self, y_train, y_test):\n",
    "        # print(datetime.datetime.now().strftime('START:  %Y-%m-%d, %H:%M:%S'))\n",
    "        print(f'\\nBaseline (y_train):')\n",
    "        print(f'  - count:\\n{y_train.value_counts()}')\n",
    "        print(f'  - percent:\\n{y_train.value_counts(normalize=True)}\\n')\n",
    "        print(f'\\nBaseline (y_test):')\n",
    "        print(f'  - count:\\n{y_test.value_counts()}')\n",
    "        print(f'  - percent:\\n{y_test.value_counts(normalize=True)}\\n')\n",
    "        print(f'\\nSTATS (y_train):')\n",
    "        self.print_train_stats()\n",
    "        print(f'\\nSTATS (y_test):')\n",
    "        self.print_stats()\n",
    "        print(f'  - Model, BEST SCORE: {self.model.best_score_}')\n",
    "        # print(datetime.datetime.now().strftime('\\nFINISH: %Y-%m-%d, %H:%M:%S'))\n",
    "\n",
    "    \n",
    "    def set_all_score(self):\n",
    "        self.scores = {\n",
    "            'R2 Score': self.test_r2_score, \n",
    "            'RMSE': self.test_rmse, \n",
    "            'MSE': self.test_mse, \n",
    "            'MAE': self.test_mae, \n",
    "        }\n",
    "        self.train_scores = {\n",
    "            'Train R2 Score': self.train_r2_score, \n",
    "            'Train RMSE': self.train_rmse, \n",
    "            'Train MSE': self.train_mse, \n",
    "            'Train MAE': self.train_mae, \n",
    "        }\n",
    "    \n",
    "    def print_stats(self):\n",
    "        for s,v in self.scores.items():\n",
    "            print(f'  - {s}:\\n        {v}')\n",
    "        print(f'\\nPIPE: {self.pipe}')\n",
    "        print(f'\\nbest params: {self.best_params_}')\n",
    "    \n",
    "    def print_train_stats(self):\n",
    "        for s,v in self.train_scores.items():\n",
    "            print(f'  - {s}:\\n        {v}')\n",
    "    \n",
    "    def set_y_pred(self, X):\n",
    "        if(self.y_thresh == -1):\n",
    "            return self.model.predict(X)\n",
    "        else:\n",
    "            return np.abs(np.where(self.model.predict(X) < self.y_thresh, 0, 1))\n",
    "    \n",
    "    def set_y_pred_inv(self, X):\n",
    "        return np.abs(np.where(self.model.predict(X) < self.y_thresh, 0, 1) - 1)\n",
    "    \n",
    "    def set_r2_score(self, y_true, y_predict):\n",
    "        return r2_score(y_true, y_predict)\n",
    "        \n",
    "    def set_rmse(self, y_true, y_predict):\n",
    "        return mean_squared_error(y_true, y_predict, squared=False)\n",
    "    \n",
    "    def set_mse(self, y_true, y_predict):\n",
    "        return mean_squared_error(y_true, y_predict, squared=True)\n",
    "        \n",
    "    def set_mae(self, y_true, y_predict):\n",
    "        return mean_absolute_error(y_true, y_predict)\n",
    "    \n",
    "    def check_y(self, y_true, y_pred):\n",
    "        y_compare = np.where(y_true == y_pred, 1, 0)\n",
    "        print(np.asarray((np.unique(y_compare, return_counts=True))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08a6bf0-378d-4627-b439-20e4be3ebd6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a307541-8f92-4c5b-aa97-eea7bc95c231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
